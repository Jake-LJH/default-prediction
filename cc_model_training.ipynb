{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ccDefaultPred.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jake-LJH/default-prediction/blob/master/cc_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlWwc-OdMLxy"
      },
      "source": [
        "#Data Set Information:\n",
        "\n",
        "This research aimed at the case of customers default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel â€œSorting Smoothing Method to estimate the real probability of default. \n",
        "\n",
        "With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.\n",
        "\n",
        "Link: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#\n",
        "\n",
        "\n",
        "##Attribute Information:\n",
        "\n",
        "This research employed a binary variable, default payment (Yes = <code>1</code>, No = <code>0</code>), as the response variable. \n",
        "\n",
        "There are 25 variables:\n",
        "\n",
        "* ID: ID of each client\n",
        "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
        "* SEX: Gender (1=male, 2=female)\n",
        "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
        "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
        "* AGE: Age in years\n",
        "* PAY_0: Repayment status in September, 2005 \n",
        "\n",
        "Scale: \n",
        "\n",
        "-2 = Balance paid in full and no transactions this period (we may refer to this credit card account as having been 'inactive' this period)\n",
        "\n",
        "-1 = Balance paid in full, but account has a positive balance at end of period due to recent transactions for which payment has not yet come due\n",
        "\n",
        "0 = Customer paid the minimum due amount, but not the entire balance. I.e., the customer paid enough for their account to remain in good standing, but did revolve a balance, \n",
        "\n",
        "1 = payment delay for one month, 2 = payment delay for two months, … 8=payment delay for eight months, 9 = payment delay for nine months and above\n",
        "\n",
        "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
        "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
        "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
        "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
        "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
        "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
        "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
        "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
        "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
        "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
        "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
        "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
        "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
        "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
        "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
        "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
        "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
        "* default.payment.next.month: Default payment (1=yes, 0=no)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYrPoqluqiuI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Import all the metrics for validation and evaluation\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "#ROC Curve\n",
        "from sklearn.metrics import plot_roc_curve"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llBFTERFgjpA"
      },
      "source": [
        "# Data Exploratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv_Tbt8TrLVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "6aff629f-38f3-488c-96df-68079f179fe4"
      },
      "source": [
        "dataset = pd.read_excel('/content/drive/MyDrive/credit card default data/default of credit card clients.xls',skiprows=1,index_col=0)\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-752973523781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/credit card default data/default of credit card clients.xls'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/credit card default data/default of credit card clients.xls'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF481DwlsNn9"
      },
      "source": [
        "print(\"Shape of dataset \"+str(dataset.shape))\n",
        "print('*'*40)\n",
        "print(dataset.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELPeB5vniMDa"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km5DIVIGiOEp"
      },
      "source": [
        "print(dataset.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVhRdemsiRfb"
      },
      "source": [
        "dataset.BILL_AMT1_OVER_LIMIT_BAL.plot(kind='box')\n",
        "plt.title('Ratio of Bill Amount in September vs Credit Limit')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7qtNjuuitOJ"
      },
      "source": [
        "# Data Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VgivI3wisiM"
      },
      "source": [
        "X = df2.drop('default payment next month', axis=1)\n",
        "y = df2['default payment next month']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhlRDiLqi5aT"
      },
      "source": [
        "X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uECBcVKuuwwp"
      },
      "source": [
        "numeric_cols = X[['LIMIT_BAL','AGE',\t'BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6','SEX','EDUCATION','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']].columns\n",
        "\n",
        "print(numeric_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcrL3ynLuy9j"
      },
      "source": [
        "numeric_transformers = Pipeline(steps=[\n",
        "                               ('scaler',StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "                    ('num',numeric_transformers, numeric_cols)\n",
        "                 \n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqr6kgH1vBgu"
      },
      "source": [
        "# Handling Class Imbalance using undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pDmuBsdvA3K"
      },
      "source": [
        "# visualize the target variable\n",
        "g = sns.countplot(df2['default payment next month'])\n",
        "g.set_xticklabels(['Not Default','Default'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUFd_JyIvHRb"
      },
      "source": [
        "# class count\n",
        "class_count_0, class_count_1 = df2['default payment next month'].value_counts()\n",
        "\n",
        "# Separate class\n",
        "class_0 = df2[df2['default payment next month'] == 0]\n",
        "class_1 = df2[df2['default payment next month'] == 1]\n",
        "\n",
        "# print the shape of the class\n",
        "print('class 0:', class_0.shape)\n",
        "print('class 1:', class_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkjjUCVJE2HC"
      },
      "source": [
        "#Under sample the non-default class\n",
        "class_0_under = class_0.sample(class_count_1)\n",
        "\n",
        "#concatenate the equalized default and non-default data\n",
        "test_under = pd.concat([class_0_under, class_1], axis=0)\n",
        "\n",
        "print(\"total class of 1 and 0:\",test_under['default payment next month'].value_counts())\n",
        "\n",
        "# plot the count after under-sampeling\n",
        "test_under['default payment next month'].value_counts().plot(kind='bar', title='count (target)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKjI6imlGSc3"
      },
      "source": [
        "X_undersample = test_under.drop('default payment next month', axis=1)\n",
        "y_undersample = test_under['default payment next month']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sex6B5VLG4h2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_undersample, x_test_undersample, Y_train_undersample, y_test_undersample = train_test_split(X_undersample, y_undersample, test_size = 0.20, random_state=42)\n",
        "X_train_undersample.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdDPPIkwH3Rl"
      },
      "source": [
        "classifiers = [\n",
        "               GaussianNB(),\n",
        "               KNeighborsClassifier(),\n",
        "               LinearSVC(),\n",
        "               LogisticRegression(random_state=1),\n",
        "               RandomForestClassifier(),\n",
        "               DecisionTreeClassifier(),\n",
        "               XGBClassifier(),\n",
        "               BernoulliNB(),                              \n",
        "               ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTtVBIJ_HNV_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "import pandas as pd\n",
        "params = []\n",
        "scores = []\n",
        "for clf in classifiers:\n",
        "  pipeline = Pipeline(\n",
        "      steps =[\n",
        "              ('preprocessor',preprocessor),\n",
        "              ('classifier',clf)\n",
        "      ]\n",
        "  )\n",
        "  #Fit the model\n",
        "  pipeline.fit(X_train_undersample, Y_train_undersample)\n",
        "\n",
        "\n",
        "  #getting the score of the classifiers\n",
        "  score = pipeline.score(x_test_undersample,y_test_undersample)\n",
        "  print(\"%s score : %.3f\" %(clf.__class__.__name__, score))\n",
        "\n",
        "\n",
        "  y_pred_undersample = pipeline.predict(x_test_undersample)\n",
        "  roc = roc_auc_score(y_test_undersample, y_pred_undersample)\n",
        "  acc = accuracy_score(y_test_undersample, y_pred_undersample)\n",
        "  prec = precision_score(y_test_undersample, y_pred_undersample)\n",
        "  rec = recall_score(y_test_undersample,y_pred_undersample)\n",
        "  f1 = f1_score(y_test_undersample, y_pred_undersample)\n",
        "  \n",
        "  \n",
        "  cols = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC']\n",
        "  score = [clf.__class__.__name__, acc, prec, rec, f1, roc]\n",
        "\n",
        "  scores.append(score)    \n",
        "            \n",
        "  scores_df = pd.DataFrame(scores, columns=cols)\n",
        "  list_params = [pipeline, score, x_test_undersample, y_test_undersample, clf.__class__.__name__]\n",
        "  params.append(list_params)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWCpDUjcva17"
      },
      "source": [
        "#Scores\n",
        "print(scores_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1UTke6OHan7"
      },
      "source": [
        "#Choose the best model and create a pipeline\n",
        "rf_clf = RandomForestClassifier()\n",
        "final_pipeline = Pipeline(\n",
        "    steps = [\n",
        "             ('preprocessor', preprocessor),\n",
        "             ('classifier', rf_clf)\n",
        "    ]\n",
        ")\n",
        "final_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CjmxNzBvgG-"
      },
      "source": [
        "rf_model = final_pipeline.fit(X_train_undersample, Y_train_undersample)\n",
        "y_pred_undersample = rf_model.predict(x_test_undersample)\n",
        "\n",
        "cm = confusion_matrix(y_test_undersample, y_pred_undersample)\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\" ,fmt =\".0f\");\n",
        "\n",
        "roc = plot_roc_curve(rf_model, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJBHngyvrAN"
      },
      "source": [
        "report = classification_report(y_test_undersample, y_pred_undersample)\n",
        "print(\"Report : \\n{}\".format(report))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3by6wufF9T"
      },
      "source": [
        "\n",
        "y_pred = rf_model.predict(x_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\" ,fmt =\".0f\");\n",
        "\n",
        "roc = plot_roc_curve(rf_model, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yGMRix9fcwH"
      },
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Report : \\n{}\".format(report))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhP83BKHv1hW"
      },
      "source": [
        "# Feature Ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-E8sTx3xI-6"
      },
      "source": [
        "def plot_most_important_features(feat_imp, method='MDI', \n",
        "                                 n_features=10, bottom=False):\n",
        "    '''\n",
        "    Function for plotting the top/bottom x features in terms of their importance.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    feat_imp : pd.Series\n",
        "        A pd.Series with calculated feature importances\n",
        "    method : str\n",
        "        A string representing the method of calculating the importances.\n",
        "        Used for the title of the plot.\n",
        "    n_features : int\n",
        "        Number of top/bottom features to plot\n",
        "    bottom : boolean\n",
        "        Indicates if the plot should contain the bottom feature importances.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    ax : matplotlib.axes._subplots.AxesSubplot\n",
        "        Ax cointaining the plot\n",
        "    '''\n",
        "    \n",
        "    if bottom:\n",
        "        indicator = 'Bottom'\n",
        "        feat_imp = feat_imp.sort_values(ascending=True)\n",
        "    else:\n",
        "        indicator = 'Top'\n",
        "        feat_imp = feat_imp.sort_values(ascending=False)\n",
        "        \n",
        "    ax = feat_imp.head(n_features).plot.barh()\n",
        "    ax.invert_yaxis()\n",
        "    ax.set(title=('Feature importance - '\n",
        "                  f'{method} ({indicator} {n_features})'), \n",
        "           xlabel='Importance', \n",
        "           ylabel='Feature')\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0kbesr4vumn"
      },
      "source": [
        "feat_names = np.r_[numeric_cols]\n",
        "rf_classifier = best_model.named_steps['classifier']\n",
        "rf_feat_imp = pd.DataFrame(rf_classifier.feature_importances_,\n",
        "                           index=feat_names,\n",
        "                           columns=['mdi'])\n",
        "rf_feat_imp = rf_feat_imp.sort_values('mdi', ascending=False)\n",
        "rf_feat_imp['cumul_importance_mdi'] = np.cumsum(rf_feat_imp.mdi)\n",
        "\n",
        "plot_most_important_features(rf_feat_imp.mdi, \n",
        "                             method='MDI')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}